{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HjNCQftEBkXc"
   },
   "source": [
    "# Author : Manas Mahale <<manas.mahale@bcp.edu.in>>\n",
    "---\n",
    "### [ResNet](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NilSkBKhPthJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7NNtOWlBkXh"
   },
   "source": [
    "### setting random seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QmwmcXuPuLo"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "classes = ['Drug','Drug Like','Non Drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('./Data/processed/X_train.pkl').values\n",
    "y_train = pd.read_pickle('./Data/processed/y_train.pkl').values\n",
    "X_test  = pd.read_pickle('./Data/processed/X_test.pkl').values\n",
    "y_test  = pd.read_pickle('./Data/processed/y_test.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(np.concatenate([list(i) for i in X_train])))\n",
    "vocab_ = list(set(np.concatenate([list(i) for i in X_test])))\n",
    "vocab.extend(vocab_)\n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for n, i in enumerate(vocab):\n",
    "    zero = np.zeros(len(vocab))\n",
    "    zero[n]=1\n",
    "    d[i] = zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_one_hot_encode_smiles(smiles, pad_len = max(max([len(i) for i in X_train]),max([len(i) for i in X_test]))):\n",
    "    return np.array([d[smiles[i]] if i < len(smiles) else np.zeros(len(vocab)) for i in range(pad_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val   = np.array([padded_one_hot_encode_smiles(i) for i in X_train[0:1000]]).astype(np.float32)\n",
    "X_train = np.array([padded_one_hot_encode_smiles(i) for i in X_train[1000:]]).astype(np.float32)\n",
    "X_test  = np.array([padded_one_hot_encode_smiles(i) for i in X_test]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val   = y_train[0:1000]\n",
    "y_train = y_train[1000:]\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append([X_train[i], y_train[i]])\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append([X_test[i], y_test[i]])\n",
    "\n",
    "val_data = []\n",
    "for i in range(len(X_val)):\n",
    "    val_data.append([X_val[i], y_val[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_iterator  = data.DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_iterator = data.DataLoader(val_data, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvkp1FEhBkYR"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao_fIYG2BkYU"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygLIMUX6BkYX"
   },
   "outputs": [],
   "source": [
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFMwBDRVBkYc"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                               stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "            \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "            \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIFUiYaCBkYg"
   },
   "outputs": [],
   "source": [
    "resnet18_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [2,2,2,2],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet34_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [3,4,6,3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 4, 23, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet152_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 8, 36, 3],\n",
    "                                channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "e0d5f6ba52604352a6484d1907385629",
      "73733f1d2af0455890e9d6f695321d89",
      "9e26aa8e760c41c4bcd81d121abb8a54",
      "d1868678a8d2487a85394a7eb6d85608",
      "dcd14c4f39ba40b1924df3921551a759",
      "2bfc54026555415b819aef84868882a0",
      "33af98c97e6141f3bfc08f9cedb4dbd0",
      "6237aa6a8e1843789e503390f5dcbd0d"
     ]
    },
    "colab_type": "code",
    "id": "qsjfsiUhRZUD",
    "outputId": "cdb95e54-4c8c-4fcf-a893-ed88a9c5650f"
   },
   "outputs": [],
   "source": [
    "# pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18')\n",
    "# pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34')\n",
    "pretrained_model = models.resnet50(pretrained = False)\n",
    "# pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50')\n",
    "# pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101')\n",
    "# pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf6xf2WVcNfY"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 3\n",
    "conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "fc    = nn.Linear(in_features=2048, out_features=3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ol3c207BkYz"
   },
   "outputs": [],
   "source": [
    "pretrained_model.fc = fc\n",
    "pretrained_model.conv1 = conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5rk-jdoBkY1"
   },
   "outputs": [],
   "source": [
    "model = ResNet(resnet50_config, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RwlzAhurBkY7",
    "outputId": "3ea4d86b-08d2-4b83-e879-b15c61649e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 23,507,907 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAmuYsW0BkY9"
   },
   "source": [
    "---\n",
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Cuqluk1ZNOW"
   },
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JSiXTj3ZfwJ"
   },
   "outputs": [],
   "source": [
    "# class LRFinder:\n",
    "#     def __init__(self, model, optimizer, criterion, device):\n",
    "        \n",
    "#         self.optimizer = optimizer\n",
    "#         self.model = model\n",
    "#         self.criterion = criterion\n",
    "#         self.device = device\n",
    "        \n",
    "#         torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "#     def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
    "#                    smooth_f = 0.05, diverge_th = 5):\n",
    "        \n",
    "#         lrs = []\n",
    "#         losses = []\n",
    "#         best_loss = float('inf')\n",
    "\n",
    "#         lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "        \n",
    "#         iterator = IteratorWrapper(iterator)\n",
    "        \n",
    "#         for iteration in range(num_iter):\n",
    "\n",
    "#             loss = self._train_batch(iterator)\n",
    "\n",
    "#             #update lr\n",
    "#             lr_scheduler.step()\n",
    "            \n",
    "#             lrs.append(lr_scheduler.get_lr()[0])\n",
    "\n",
    "#             if iteration > 0:\n",
    "#                 loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "                \n",
    "#             if loss < best_loss:\n",
    "#                 best_loss = loss\n",
    "\n",
    "#             losses.append(loss)\n",
    "            \n",
    "#             if loss > diverge_th * best_loss:\n",
    "#                 print(\"Stopping early, the loss has diverged\")\n",
    "#                 break\n",
    "                       \n",
    "#         #reset model to initial parameters\n",
    "#         model.load_state_dict(torch.load('init_params.pt'))\n",
    "                    \n",
    "#         return lrs, losses\n",
    "\n",
    "#     def _train_batch(self, iterator):\n",
    "        \n",
    "#         self.model.train()\n",
    "        \n",
    "#         self.optimizer.zero_grad()\n",
    "        \n",
    "#         x, y = iterator.get_batch()\n",
    "        \n",
    "#         x = x.to(self.device)\n",
    "#         y = y.to(self.device)\n",
    "        \n",
    "#         y_pred, _ = self.model(x.unsqueeze(1))\n",
    "                \n",
    "#         loss = self.criterion(y_pred, y)\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         self.optimizer.step()\n",
    "        \n",
    "#         return loss.item()\n",
    "\n",
    "# class ExponentialLR(_LRScheduler):\n",
    "#     def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "#         self.end_lr = end_lr\n",
    "#         self.num_iter = num_iter\n",
    "#         super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "#     def get_lr(self):\n",
    "#         curr_iter = self.last_epoch + 1\n",
    "#         r = curr_iter / self.num_iter\n",
    "#         return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
    "\n",
    "# class IteratorWrapper:\n",
    "#     def __init__(self, iterator):\n",
    "#         self.iterator = iterator\n",
    "#         self._iterator = iter(iterator)\n",
    "\n",
    "#     def __next__(self):\n",
    "#         try:\n",
    "#             inputs, labels = next(self._iterator)\n",
    "#         except StopIteration:\n",
    "#             self._iterator = iter(self.iterator)\n",
    "#             inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "#         return inputs, labels\n",
    "\n",
    "#     def get_batch(self):\n",
    "#         return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fxtlrpfWZk8t",
    "outputId": "d4a73dc9-ab5a-428b-a0ed-c3d76fd4dc3e"
   },
   "outputs": [],
   "source": [
    "# END_LR = 10\n",
    "# NUM_ITER = 100\n",
    "\n",
    "# lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "# lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBzT3twzZnAW"
   },
   "outputs": [],
   "source": [
    "# def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
    "    \n",
    "#     if skip_end == 0:\n",
    "#         lrs = lrs[skip_start:]\n",
    "#         losses = losses[skip_start:]\n",
    "#     else:\n",
    "#         lrs = lrs[skip_start:-skip_end]\n",
    "#         losses = losses[skip_start:-skip_end]\n",
    "    \n",
    "#     fig = plt.figure(figsize = (16,8))\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     ax.plot(lrs, losses)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_xlabel('Learning rate')\n",
    "#     ax.set_ylabel('Loss')\n",
    "#     ax.grid(True, 'both', 'x')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "BnIQz0g4Zp5n",
    "outputId": "ff827ee8-c933-49a9-f5ac-12d6edf50c50"
   },
   "outputs": [],
   "source": [
    "# plot_lr_finder(lrs, losses, skip_start = 30, skip_end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDjS7JvNBkZR"
   },
   "outputs": [],
   "source": [
    "FOUND_LR = 1e-3\n",
    "\n",
    "params = [\n",
    "          {'params': model.conv1.parameters() , 'lr': FOUND_LR / 12},\n",
    "          {'params': model.bn1.parameters()   , 'lr': FOUND_LR / 10},\n",
    "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
    "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
    "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
    "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
    "          {'params': model.fc.parameters()}\n",
    "         ]\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params, lr = FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riS8zV2IxVMK"
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = len(train_iterator)\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "\n",
    "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
    "\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                    max_lr = MAX_LRS,\n",
    "                                    total_steps = TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_EKb_cNadbI"
   },
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k = 3):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr6Je0jMafsp"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in tqdm(iterator, ncols=1000, total = len(iterator)):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x.unsqueeze(1))\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss  /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85FW74KaakI_"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (x, y) in tqdm(iterator, ncols=1000, total = len(iterator)):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x.unsqueeze(1))\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkR6LzakamOV"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "lvoyX823apEN",
    "outputId": "0cb310cb-9016-4cca-dcbb-df2f04345e99",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338b7bf6719476da07e64f28b463c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa31edc1b1849aca2694253ae3d2658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, leave=False):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './CHEM_RESNET.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "          f'Train Acc : {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "          f'Valid Acc : {valid_acc_5*100:6.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fOla2axMBkZk",
    "outputId": "a8178c45-adaa-4b00-bf59-0a1de0eb4363",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./CHEM_RESNET.pt'))\n",
    "\n",
    "test_loss, test_acc_1, test_acc_5 = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | ' \\\n",
    "      f'Test Acc : {test_acc_5*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORmtSernBkZo"
   },
   "source": [
    "---\n",
    "## Examining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlCBiYxQbi4s"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x.unsqueeze(1))\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmfK-IZ6bmlz"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zR__HoORbpXV"
   },
   "outputs": [],
   "source": [
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hupBoXNhbqe_"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "    \n",
    "    fig = plt.figure(dpi=300);\n",
    "    ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = confusion_matrix(labels, pred_labels);\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "    fig.delaxes(fig.axes[1]) #delete colorbar\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "08XMzduObsMa",
    "outputId": "10e2d465-b7dd-4bb3-c3b8-73bd6453e3d5"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(labels, pred_labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgSkMA9dbzy8"
   },
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8DbVGfYb0N_"
   },
   "outputs": [],
   "source": [
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5UzPHw29QVi"
   },
   "outputs": [],
   "source": [
    "def get_representations(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x.unsqueeze(1))\n",
    "\n",
    "            outputs.append(y_pred.cpu())\n",
    "            labels.append(y)\n",
    "        \n",
    "    outputs = torch.cat(outputs, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "\n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYvJXnuu9by8"
   },
   "outputs": [],
   "source": [
    "outputs, labels = get_representations(model, train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C0vTaVm9dha"
   },
   "outputs": [],
   "source": [
    "def get_pca(data, n_components = 2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHQfixt09fMO"
   },
   "outputs": [],
   "source": [
    "def plot_representations(data, labels, classes, n_images = None):\n",
    "            \n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "                \n",
    "    fig = plt.figure(dpi=400)\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'viridis')\n",
    "    handles, _ = scatter.legend_elements(num = None)\n",
    "    legend = plt.legend(handles = handles, labels = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "TpZQLiLZ9hdh",
    "outputId": "ff8114df-56ea-4d08-c628-d00ced87382c"
   },
   "outputs": [],
   "source": [
    "output_pca_data = get_pca(outputs)\n",
    "plot_representations(output_pca_data, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pz6yxrS29i9D"
   },
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components = 2, n_images = None):\n",
    "    \n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        \n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "fe8v2Z2v9koj",
    "outputId": "41f8e18d-611b-43e9-90b8-8aec133a659c"
   },
   "outputs": [],
   "source": [
    "output_tsne_data = get_tsne(outputs)\n",
    "plot_representations(output_tsne_data, labels, classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5 - ResNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bfc54026555415b819aef84868882a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33af98c97e6141f3bfc08f9cedb4dbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6237aa6a8e1843789e503390f5dcbd0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73733f1d2af0455890e9d6f695321d89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e26aa8e760c41c4bcd81d121abb8a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bfc54026555415b819aef84868882a0",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dcd14c4f39ba40b1924df3921551a759",
      "value": 102502400
     }
    },
    "d1868678a8d2487a85394a7eb6d85608": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6237aa6a8e1843789e503390f5dcbd0d",
      "placeholder": "​",
      "style": "IPY_MODEL_33af98c97e6141f3bfc08f9cedb4dbd0",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 114MB/s]"
     }
    },
    "dcd14c4f39ba40b1924df3921551a759": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e0d5f6ba52604352a6484d1907385629": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e26aa8e760c41c4bcd81d121abb8a54",
       "IPY_MODEL_d1868678a8d2487a85394a7eb6d85608"
      ],
      "layout": "IPY_MODEL_73733f1d2af0455890e9d6f695321d89"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
